# 메인 메모리, MMU, 가상 메모리 및 페이지 교체

---

## 1. 메인 메모리 (Main Memory)

- **정의**:  
  CPU가 직접 접근할 수 있는 주기억장치로, 실행 중인 프로그램의 명령어와 데이터를 저장하는 역할을 한다.

- **주요 특징**:
  - **주소 기반 저장**: 주소가 할당된 일련의 바이트로 구성
  - **CPU와의 상호작용**:
    - CPU는 레지스터가 지정한 주소로부터 명령어를 읽어 실행한다.
    - 필요한 데이터가 메모리에 없을 경우, 데이터를 우선 메모리로 가져오는 과정(페이지 부재)이 발생함.

---

## 2. 메모리 관리 장치 (MMU)

- **역할 및 기능**:  
  MMU는 CPU와 메인 메모리 사이에서 논리(가상) 주소와 물리 주소 간의 변환을 수행함.

  - **주소 변환**:  
    가상 주소를 물리 주소로 매핑하여 프로그램이 실제 메모리에 접근할 수 있도록 한다.

  - **메모리 보호**:

    - 각 프로세스는 독립적인 주소 공간을 가지며, **base**와 **limit** 레지스터를 이용해 접근 가능한 영역을 설정함.
    - 예) `base <= x < base + limit` 범위를 벗어난 접근 시 trap 발생.

  - **가상 메모리 지원**:  
    사용자가 직접 메모리 주소를 관리할 필요 없이, 프로그램은 가상 주소 공간을 통해 메모리를 사용할 수 있게 한다.

  - **캐시 관리 지원**:  
    메모리 접근 속도를 향상시키기 위해 캐시와의 연동 및 관리도 수행한다.

---

## 3. 가상 메모리와 메모리 과할당

- **가상 메모리 (Virtual Memory)**:

  - **목적**:  
    물리 메모리보다 큰 가상 주소 공간을 제공하여, 다중 프로세스를 동시에 실행하고, 프로그램 전체가 물리 메모리에 올라오지 않아도 실행할 수 있도록 한다.

  - **주요 기법**:  
    **요구 페이징 (Demand Paging)**을 통해 실행 시 실제로 필요한 페이지만 메모리에 적재한다.

  - **장점**:
    - 물리 메모리의 한계를 극복하여 다수의 프로그램 실행.
    - 응답 시간 유지 및 CPU 이용률, 처리율 향상.
    - 불필요한 페이지의 적재를 줄여, 메모리 사용 효율 최적화.

- **메모리 과할당 (Over-allocating)**:

  - **개념**:  
    실제 메모리 용량보다 큰 메모리 공간을 프로세스에 할당하는 방식으로, 사용자가 이를 인지하지 못하도록 가상 메모리 기법을 활용한다.

  - **문제 상황 및 해결**:
    - **페이지 부재 발생**: 실행 중 필요한 페이지가 메모리에 없으면, 페이지 부재가 발생한다.
    - **빈 프레임 부족**: 빈 프레임이 없을 경우, victim 페이지를 선택하여 swap out 후 새 페이지를 적재하는 **페이지 교체**가 일어남.

---

## 4. 페이지 교체 과정 및 오버헤드 최소화

- **페이지 교체 기본 흐름**:

  1. **페이지 부재(Page Fault)**: 필요한 페이지가 메모리에 없으면, 디스크에서 해당 페이지 위치를 찾음.
  2. **빈 프레임 확인**:
     - 빈 프레임이 있으면 해당 프레임에 페이지 적재.
     - 빈 프레임이 없으면, 페이지 교체 알고리즘에 따라 victim 페이지를 선정.
  3. **Victim 페이지 처리**:
     - **변경(Dirty) 비트 확인**:
       - **Set 상태**: 메모리와 디스크 간 내용이 달라, 디스크에 기록 필요.
       - **Clear 상태**: 내용이 일치하므로, 기록 없이 바로 교체.
  4. **페이지 적재 및 테이블 업데이트**:  
     새 페이지를 빈 프레임에 적재하고, 페이지 테이블을 갱신하여 프로세스 실행 재개.

- **오버헤드 최소화 방법**:
  - **변경 비트 활용**: 불필요한 디스크 쓰기를 줄여 오버헤드를 감소.
  - **효율적인 교체 알고리즘**: 페이지 부재 확률을 줄일 수 있는 교체 기법 선택.

---

## 5. 페이지 교체 알고리즘

- **FIFO (First-In, First-Out)**:

  - **원리**: 가장 먼저 메모리에 적재된 페이지를 교체.
  - **장단점**:
    - 구현이 간단함.
    - Belady의 모순(더 많은 프레임이 오히려 높은 페이지 부재율 발생 가능) 문제 존재.

- **OPT (Optimal Page Replacement)**:

  - **원리**: 미래에 가장 오래 사용되지 않을 페이지를 교체 대상으로 선택.
  - **특징**:
    - 이론상 최적의 성능 제공.
    - 미래 예측이 불가능해 실제 구현은 어려움.

- **LRU (Least Recently Used)**:

  - **원리**: 최근에 사용되지 않은 페이지를 선택하여 교체.
  - **특징**:
    - FIFO보다 효과적이나, 구현 시 추가 오버헤드가 발생할 수 있음.

- **LFU (Least Frequently Used)**:

  - **원리**: 참조 횟수가 가장 적은 페이지를 교체.
  - **한계**: 특정 페이지가 과거에 많이 사용되었더라도, 현재는 사용되지 않을 수 있음.

- **MFU (Most Frequently Used)**:
  - **원리**: 참조 횟수가 높은 페이지는 이미 충분히 사용되었으리라 가정하고 교체.
  - **특징**:
    - 일반적으로 OPT 알고리즘에 근사하지 못해 널리 사용되지는 않음.

---

## 6. 캐시 메모리와 지역성(Locality)

- **캐시 메모리**:

  - **정의**:  
    CPU와 메인 메모리 간의 속도 차이를 보완하기 위해, 자주 사용하는 데이터를 임시 저장하는 고속 기억 장치.
  - **구성**:  
    일반적으로 SRAM을 사용하며, DRAM 기반 메인 메모리보다 빠른 접근 속도를 제공한다.
  - **작동 원리**:
    - **캐시 히트**: 필요한 데이터가 캐시에 존재하면 즉시 접근.
    - **캐시 미스**: 캐시에 없으면 메인 메모리에서 데이터를 읽어 캐시에 저장 후 접근.

- **지역성의 원리**:

  - **시간 지역성 (Temporal Locality)**: 최근에 참조된 데이터는 곧 다시 참조될 가능성이 높음.
  - **공간 지역성 (Spatial Locality)**: 인접한 주소의 데이터도 함께 참조될 가능성이 높음.

- **캐싱 라인**:
  - 데이터들을 일정 크기의 블록 단위(라인)로 저장하여, 빠른 검색 및 접근을 가능하게 함.

---

## 7. 캐시 방식 (Cache Mapping Methods)

1. **직접 매핑 (Direct Mapping)**:

   - **원리**:  
     메모리의 각 블록은 캐시의 특정 위치(라인)에만 매핑된다. 즉, 메모리 블록 주소의 일부 비트가 캐시 라인 번호를 결정함.
   - **장점**:  
     구조가 단순하여 구현이 용이하며, 빠른 접근이 가능.
   - **단점**:  
     서로 다른 메모리 블록이 동일한 캐시 라인으로 매핑될 경우 충돌이 발생할 수 있으며, 이로 인해 캐시 미스가 빈번해질 수 있다.

2. **완전 연관 매핑 (Fully Associative Mapping)**:

   - **원리**:  
     메모리의 어떤 블록도 캐시의 어느 라인에나 저장될 수 있으며, 검색 시 전체 캐시를 확인한다.
   - **장점**:  
     충돌이 최소화되며, 캐시 공간을 효율적으로 활용할 수 있음.
   - **단점**:  
     전체 캐시를 검색해야 하므로 하드웨어 복잡성이 증가하고, 오버헤드가 증가할 수 있다.

3. **집합 연관 매핑 (Set-Associative Mapping)**:

   - **원리**:  
     캐시를 여러 개의 집합(set)으로 분할하고, 각 집합 내에서 완전 연관 매핑을 적용하는 방식.
   - **장점**:  
     직접 매핑과 완전 연관 매핑의 장점을 절충하여, 충돌 가능성을 낮추면서도 하드웨어 구현의 복잡성을 줄일 수 있음.
   - **예시**:  
     2-way, 4-way, 8-way 집합 연관 캐시 등으로 구현되며, 각 집합 내에서 여러 라인 중 하나에 데이터를 저장한다.

4. **쓰기 정책 (Write Policies)**:
   - **Write-Through**:  
     캐시와 메인 메모리 모두에 동시에 데이터를 기록함. 데이터 일관성이 보장되지만, 쓰기 연산 시 성능 저하가 발생 가능.
   - **Write-Back**:  
     캐시에만 데이터를 기록하고, 캐시 라인의 변경 비트(Dirty Bit)를 설정하여 나중에 메인 메모리에 기록한다.

---
